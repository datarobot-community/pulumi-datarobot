// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace DataRobotPulumi.Datarobot
{
    /// <summary>
    /// Batch Prediction Job Definition
    /// </summary>
    [DatarobotResourceType("datarobot:index/batchPredictionJobDefinition:BatchPredictionJobDefinition")]
    public partial class BatchPredictionJobDefinition : global::Pulumi.CustomResource
    {
        /// <summary>
        /// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
        /// </summary>
        [Output("abortOnError")]
        public Output<bool> AbortOnError { get; private set; } = null!;

        /// <summary>
        /// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
        /// </summary>
        [Output("chunkSize")]
        public Output<object?> ChunkSize { get; private set; } = null!;

        /// <summary>
        /// Mapping with column renaming for output table.
        /// </summary>
        [Output("columnNamesRemapping")]
        public Output<ImmutableDictionary<string, string>?> ColumnNamesRemapping { get; private set; } = null!;

        /// <summary>
        /// CSV intake and output settings.
        /// </summary>
        [Output("csvSettings")]
        public Output<Outputs.BatchPredictionJobDefinitionCsvSettings> CsvSettings { get; private set; } = null!;

        /// <summary>
        /// The ID of the deployment to use for the batch prediction job.
        /// </summary>
        [Output("deploymentId")]
        public Output<string> DeploymentId { get; private set; } = null!;

        /// <summary>
        /// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
        /// </summary>
        [Output("enabled")]
        public Output<bool> Enabled { get; private set; } = null!;

        /// <summary>
        /// Which algorithm will be used to calculate prediction explanations.
        /// </summary>
        [Output("explanationAlgorithm")]
        public Output<string> ExplanationAlgorithm { get; private set; } = null!;

        /// <summary>
        /// Include the prediction_status column in the output. Defaults to False.
        /// </summary>
        [Output("includePredictionStatus")]
        public Output<bool> IncludePredictionStatus { get; private set; } = null!;

        /// <summary>
        /// Flag that enables returning of all probability columns. Defaults to True.
        /// </summary>
        [Output("includeProbabilities")]
        public Output<bool> IncludeProbabilities { get; private set; } = null!;

        /// <summary>
        /// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
        /// </summary>
        [Output("includeProbabilitiesClasses")]
        public Output<ImmutableArray<string>> IncludeProbabilitiesClasses { get; private set; } = null!;

        /// <summary>
        /// A dict configuring how data is coming from.
        /// </summary>
        [Output("intakeSettings")]
        public Output<Outputs.BatchPredictionJobDefinitionIntakeSettings> IntakeSettings { get; private set; } = null!;

        /// <summary>
        /// Compute prediction explanations for this amount of features.
        /// </summary>
        [Output("maxExplanations")]
        public Output<int> MaxExplanations { get; private set; } = null!;

        /// <summary>
        /// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
        /// </summary>
        [Output("numConcurrent")]
        public Output<int?> NumConcurrent { get; private set; } = null!;

        /// <summary>
        /// A dict configuring how scored data is to be saved.
        /// </summary>
        [Output("outputSettings")]
        public Output<Outputs.BatchPredictionJobDefinitionOutputSettings> OutputSettings { get; private set; } = null!;

        /// <summary>
        /// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
        /// </summary>
        [Output("passthroughColumns")]
        public Output<ImmutableArray<string>> PassthroughColumns { get; private set; } = null!;

        /// <summary>
        /// To pass through every column from the scoring dataset, set this to all.
        /// </summary>
        [Output("passthroughColumnsSet")]
        public Output<string?> PassthroughColumnsSet { get; private set; } = null!;

        /// <summary>
        /// Defaults to instance specified by deployment or system configuration.
        /// </summary>
        [Output("predictionInstance")]
        public Output<Outputs.BatchPredictionJobDefinitionPredictionInstance?> PredictionInstance { get; private set; } = null!;

        /// <summary>
        /// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
        /// </summary>
        [Output("predictionThreshold")]
        public Output<double?> PredictionThreshold { get; private set; } = null!;

        /// <summary>
        /// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
        /// </summary>
        [Output("predictionWarningEnabled")]
        public Output<bool> PredictionWarningEnabled { get; private set; } = null!;

        /// <summary>
        /// Defines at what intervals the job should run.
        /// </summary>
        [Output("schedule")]
        public Output<Outputs.BatchPredictionJobDefinitionSchedule?> Schedule { get; private set; } = null!;

        /// <summary>
        /// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
        /// </summary>
        [Output("skipDriftTracking")]
        public Output<bool> SkipDriftTracking { get; private set; } = null!;

        /// <summary>
        /// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
        /// </summary>
        [Output("thresholdHigh")]
        public Output<double?> ThresholdHigh { get; private set; } = null!;

        /// <summary>
        /// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
        /// </summary>
        [Output("thresholdLow")]
        public Output<double?> ThresholdLow { get; private set; } = null!;

        /// <summary>
        /// Configuration for time-series scoring.
        /// </summary>
        [Output("timeseriesSettings")]
        public Output<Outputs.BatchPredictionJobDefinitionTimeseriesSettings?> TimeseriesSettings { get; private set; } = null!;


        /// <summary>
        /// Create a BatchPredictionJobDefinition resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public BatchPredictionJobDefinition(string name, BatchPredictionJobDefinitionArgs args, CustomResourceOptions? options = null)
            : base("datarobot:index/batchPredictionJobDefinition:BatchPredictionJobDefinition", name, args ?? new BatchPredictionJobDefinitionArgs(), MakeResourceOptions(options, ""))
        {
        }

        private BatchPredictionJobDefinition(string name, Input<string> id, BatchPredictionJobDefinitionState? state = null, CustomResourceOptions? options = null)
            : base("datarobot:index/batchPredictionJobDefinition:BatchPredictionJobDefinition", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
                PluginDownloadURL = "github://api.github.com/datarobot-community/pulumi-datarobot",
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing BatchPredictionJobDefinition resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static BatchPredictionJobDefinition Get(string name, Input<string> id, BatchPredictionJobDefinitionState? state = null, CustomResourceOptions? options = null)
        {
            return new BatchPredictionJobDefinition(name, id, state, options);
        }
    }

    public sealed class BatchPredictionJobDefinitionArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
        /// </summary>
        [Input("abortOnError")]
        public Input<bool>? AbortOnError { get; set; }

        /// <summary>
        /// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
        /// </summary>
        [Input("chunkSize")]
        public Input<object>? ChunkSize { get; set; }

        [Input("columnNamesRemapping")]
        private InputMap<string>? _columnNamesRemapping;

        /// <summary>
        /// Mapping with column renaming for output table.
        /// </summary>
        public InputMap<string> ColumnNamesRemapping
        {
            get => _columnNamesRemapping ?? (_columnNamesRemapping = new InputMap<string>());
            set => _columnNamesRemapping = value;
        }

        /// <summary>
        /// CSV intake and output settings.
        /// </summary>
        [Input("csvSettings")]
        public Input<Inputs.BatchPredictionJobDefinitionCsvSettingsArgs>? CsvSettings { get; set; }

        /// <summary>
        /// The ID of the deployment to use for the batch prediction job.
        /// </summary>
        [Input("deploymentId", required: true)]
        public Input<string> DeploymentId { get; set; } = null!;

        /// <summary>
        /// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
        /// </summary>
        [Input("enabled")]
        public Input<bool>? Enabled { get; set; }

        /// <summary>
        /// Which algorithm will be used to calculate prediction explanations.
        /// </summary>
        [Input("explanationAlgorithm")]
        public Input<string>? ExplanationAlgorithm { get; set; }

        /// <summary>
        /// Include the prediction_status column in the output. Defaults to False.
        /// </summary>
        [Input("includePredictionStatus")]
        public Input<bool>? IncludePredictionStatus { get; set; }

        /// <summary>
        /// Flag that enables returning of all probability columns. Defaults to True.
        /// </summary>
        [Input("includeProbabilities")]
        public Input<bool>? IncludeProbabilities { get; set; }

        [Input("includeProbabilitiesClasses")]
        private InputList<string>? _includeProbabilitiesClasses;

        /// <summary>
        /// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
        /// </summary>
        public InputList<string> IncludeProbabilitiesClasses
        {
            get => _includeProbabilitiesClasses ?? (_includeProbabilitiesClasses = new InputList<string>());
            set => _includeProbabilitiesClasses = value;
        }

        /// <summary>
        /// A dict configuring how data is coming from.
        /// </summary>
        [Input("intakeSettings", required: true)]
        public Input<Inputs.BatchPredictionJobDefinitionIntakeSettingsArgs> IntakeSettings { get; set; } = null!;

        /// <summary>
        /// Compute prediction explanations for this amount of features.
        /// </summary>
        [Input("maxExplanations")]
        public Input<int>? MaxExplanations { get; set; }

        /// <summary>
        /// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
        /// </summary>
        [Input("numConcurrent")]
        public Input<int>? NumConcurrent { get; set; }

        /// <summary>
        /// A dict configuring how scored data is to be saved.
        /// </summary>
        [Input("outputSettings")]
        public Input<Inputs.BatchPredictionJobDefinitionOutputSettingsArgs>? OutputSettings { get; set; }

        [Input("passthroughColumns")]
        private InputList<string>? _passthroughColumns;

        /// <summary>
        /// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
        /// </summary>
        public InputList<string> PassthroughColumns
        {
            get => _passthroughColumns ?? (_passthroughColumns = new InputList<string>());
            set => _passthroughColumns = value;
        }

        /// <summary>
        /// To pass through every column from the scoring dataset, set this to all.
        /// </summary>
        [Input("passthroughColumnsSet")]
        public Input<string>? PassthroughColumnsSet { get; set; }

        /// <summary>
        /// Defaults to instance specified by deployment or system configuration.
        /// </summary>
        [Input("predictionInstance")]
        public Input<Inputs.BatchPredictionJobDefinitionPredictionInstanceArgs>? PredictionInstance { get; set; }

        /// <summary>
        /// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
        /// </summary>
        [Input("predictionThreshold")]
        public Input<double>? PredictionThreshold { get; set; }

        /// <summary>
        /// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
        /// </summary>
        [Input("predictionWarningEnabled")]
        public Input<bool>? PredictionWarningEnabled { get; set; }

        /// <summary>
        /// Defines at what intervals the job should run.
        /// </summary>
        [Input("schedule")]
        public Input<Inputs.BatchPredictionJobDefinitionScheduleArgs>? Schedule { get; set; }

        /// <summary>
        /// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
        /// </summary>
        [Input("skipDriftTracking")]
        public Input<bool>? SkipDriftTracking { get; set; }

        /// <summary>
        /// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
        /// </summary>
        [Input("thresholdHigh")]
        public Input<double>? ThresholdHigh { get; set; }

        /// <summary>
        /// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
        /// </summary>
        [Input("thresholdLow")]
        public Input<double>? ThresholdLow { get; set; }

        /// <summary>
        /// Configuration for time-series scoring.
        /// </summary>
        [Input("timeseriesSettings")]
        public Input<Inputs.BatchPredictionJobDefinitionTimeseriesSettingsArgs>? TimeseriesSettings { get; set; }

        public BatchPredictionJobDefinitionArgs()
        {
        }
        public static new BatchPredictionJobDefinitionArgs Empty => new BatchPredictionJobDefinitionArgs();
    }

    public sealed class BatchPredictionJobDefinitionState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
        /// </summary>
        [Input("abortOnError")]
        public Input<bool>? AbortOnError { get; set; }

        /// <summary>
        /// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
        /// </summary>
        [Input("chunkSize")]
        public Input<object>? ChunkSize { get; set; }

        [Input("columnNamesRemapping")]
        private InputMap<string>? _columnNamesRemapping;

        /// <summary>
        /// Mapping with column renaming for output table.
        /// </summary>
        public InputMap<string> ColumnNamesRemapping
        {
            get => _columnNamesRemapping ?? (_columnNamesRemapping = new InputMap<string>());
            set => _columnNamesRemapping = value;
        }

        /// <summary>
        /// CSV intake and output settings.
        /// </summary>
        [Input("csvSettings")]
        public Input<Inputs.BatchPredictionJobDefinitionCsvSettingsGetArgs>? CsvSettings { get; set; }

        /// <summary>
        /// The ID of the deployment to use for the batch prediction job.
        /// </summary>
        [Input("deploymentId")]
        public Input<string>? DeploymentId { get; set; }

        /// <summary>
        /// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
        /// </summary>
        [Input("enabled")]
        public Input<bool>? Enabled { get; set; }

        /// <summary>
        /// Which algorithm will be used to calculate prediction explanations.
        /// </summary>
        [Input("explanationAlgorithm")]
        public Input<string>? ExplanationAlgorithm { get; set; }

        /// <summary>
        /// Include the prediction_status column in the output. Defaults to False.
        /// </summary>
        [Input("includePredictionStatus")]
        public Input<bool>? IncludePredictionStatus { get; set; }

        /// <summary>
        /// Flag that enables returning of all probability columns. Defaults to True.
        /// </summary>
        [Input("includeProbabilities")]
        public Input<bool>? IncludeProbabilities { get; set; }

        [Input("includeProbabilitiesClasses")]
        private InputList<string>? _includeProbabilitiesClasses;

        /// <summary>
        /// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
        /// </summary>
        public InputList<string> IncludeProbabilitiesClasses
        {
            get => _includeProbabilitiesClasses ?? (_includeProbabilitiesClasses = new InputList<string>());
            set => _includeProbabilitiesClasses = value;
        }

        /// <summary>
        /// A dict configuring how data is coming from.
        /// </summary>
        [Input("intakeSettings")]
        public Input<Inputs.BatchPredictionJobDefinitionIntakeSettingsGetArgs>? IntakeSettings { get; set; }

        /// <summary>
        /// Compute prediction explanations for this amount of features.
        /// </summary>
        [Input("maxExplanations")]
        public Input<int>? MaxExplanations { get; set; }

        /// <summary>
        /// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
        /// </summary>
        [Input("numConcurrent")]
        public Input<int>? NumConcurrent { get; set; }

        /// <summary>
        /// A dict configuring how scored data is to be saved.
        /// </summary>
        [Input("outputSettings")]
        public Input<Inputs.BatchPredictionJobDefinitionOutputSettingsGetArgs>? OutputSettings { get; set; }

        [Input("passthroughColumns")]
        private InputList<string>? _passthroughColumns;

        /// <summary>
        /// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
        /// </summary>
        public InputList<string> PassthroughColumns
        {
            get => _passthroughColumns ?? (_passthroughColumns = new InputList<string>());
            set => _passthroughColumns = value;
        }

        /// <summary>
        /// To pass through every column from the scoring dataset, set this to all.
        /// </summary>
        [Input("passthroughColumnsSet")]
        public Input<string>? PassthroughColumnsSet { get; set; }

        /// <summary>
        /// Defaults to instance specified by deployment or system configuration.
        /// </summary>
        [Input("predictionInstance")]
        public Input<Inputs.BatchPredictionJobDefinitionPredictionInstanceGetArgs>? PredictionInstance { get; set; }

        /// <summary>
        /// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
        /// </summary>
        [Input("predictionThreshold")]
        public Input<double>? PredictionThreshold { get; set; }

        /// <summary>
        /// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
        /// </summary>
        [Input("predictionWarningEnabled")]
        public Input<bool>? PredictionWarningEnabled { get; set; }

        /// <summary>
        /// Defines at what intervals the job should run.
        /// </summary>
        [Input("schedule")]
        public Input<Inputs.BatchPredictionJobDefinitionScheduleGetArgs>? Schedule { get; set; }

        /// <summary>
        /// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
        /// </summary>
        [Input("skipDriftTracking")]
        public Input<bool>? SkipDriftTracking { get; set; }

        /// <summary>
        /// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
        /// </summary>
        [Input("thresholdHigh")]
        public Input<double>? ThresholdHigh { get; set; }

        /// <summary>
        /// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
        /// </summary>
        [Input("thresholdLow")]
        public Input<double>? ThresholdLow { get; set; }

        /// <summary>
        /// Configuration for time-series scoring.
        /// </summary>
        [Input("timeseriesSettings")]
        public Input<Inputs.BatchPredictionJobDefinitionTimeseriesSettingsGetArgs>? TimeseriesSettings { get; set; }

        public BatchPredictionJobDefinitionState()
        {
        }
        public static new BatchPredictionJobDefinitionState Empty => new BatchPredictionJobDefinitionState();
    }
}
