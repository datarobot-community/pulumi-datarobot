// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package datarobot

import (
	"context"
	"reflect"

	"errors"
	"github.com/datarobot-community/pulumi-datarobot/sdk/go/datarobot/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Batch Prediction Job Definition
type BatchPredictionJobDefinition struct {
	pulumi.CustomResourceState

	// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
	AbortOnError pulumi.BoolOutput `pulumi:"abortOnError"`
	// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
	ChunkSize pulumi.AnyOutput `pulumi:"chunkSize"`
	// Mapping with column renaming for output table.
	ColumnNamesRemapping pulumi.StringMapOutput `pulumi:"columnNamesRemapping"`
	// CSV intake and output settings.
	CsvSettings BatchPredictionJobDefinitionCsvSettingsOutput `pulumi:"csvSettings"`
	// The ID of the deployment to use for the batch prediction job.
	DeploymentId pulumi.StringOutput `pulumi:"deploymentId"`
	// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
	Enabled pulumi.BoolOutput `pulumi:"enabled"`
	// Which algorithm will be used to calculate prediction explanations.
	ExplanationAlgorithm pulumi.StringOutput `pulumi:"explanationAlgorithm"`
	// Include the predictionStatus column in the output. Defaults to False.
	IncludePredictionStatus pulumi.BoolOutput `pulumi:"includePredictionStatus"`
	// Flag that enables returning of all probability columns. Defaults to True.
	IncludeProbabilities pulumi.BoolOutput `pulumi:"includeProbabilities"`
	// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
	IncludeProbabilitiesClasses pulumi.StringArrayOutput `pulumi:"includeProbabilitiesClasses"`
	// A dict configuring how data is coming from.
	IntakeSettings BatchPredictionJobDefinitionIntakeSettingsOutput `pulumi:"intakeSettings"`
	// Compute prediction explanations for this amount of features.
	MaxExplanations pulumi.IntOutput `pulumi:"maxExplanations"`
	// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
	Name pulumi.StringOutput `pulumi:"name"`
	// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
	NumConcurrent pulumi.IntPtrOutput `pulumi:"numConcurrent"`
	// A dict configuring how scored data is to be saved.
	OutputSettings BatchPredictionJobDefinitionOutputSettingsOutput `pulumi:"outputSettings"`
	// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
	PassthroughColumns pulumi.StringArrayOutput `pulumi:"passthroughColumns"`
	// To pass through every column from the scoring dataset, set this to all.
	PassthroughColumnsSet pulumi.StringPtrOutput `pulumi:"passthroughColumnsSet"`
	// Defaults to instance specified by deployment or system configuration.
	PredictionInstance BatchPredictionJobDefinitionPredictionInstancePtrOutput `pulumi:"predictionInstance"`
	// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
	PredictionThreshold pulumi.Float64PtrOutput `pulumi:"predictionThreshold"`
	// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
	PredictionWarningEnabled pulumi.BoolOutput `pulumi:"predictionWarningEnabled"`
	// Defines at what intervals the job should run.
	Schedule BatchPredictionJobDefinitionSchedulePtrOutput `pulumi:"schedule"`
	// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
	SkipDriftTracking pulumi.BoolOutput `pulumi:"skipDriftTracking"`
	// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
	ThresholdHigh pulumi.Float64PtrOutput `pulumi:"thresholdHigh"`
	// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
	ThresholdLow pulumi.Float64PtrOutput `pulumi:"thresholdLow"`
	// Configuration for time-series scoring.
	TimeseriesSettings BatchPredictionJobDefinitionTimeseriesSettingsPtrOutput `pulumi:"timeseriesSettings"`
}

// NewBatchPredictionJobDefinition registers a new resource with the given unique name, arguments, and options.
func NewBatchPredictionJobDefinition(ctx *pulumi.Context,
	name string, args *BatchPredictionJobDefinitionArgs, opts ...pulumi.ResourceOption) (*BatchPredictionJobDefinition, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.DeploymentId == nil {
		return nil, errors.New("invalid value for required argument 'DeploymentId'")
	}
	if args.IntakeSettings == nil {
		return nil, errors.New("invalid value for required argument 'IntakeSettings'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource BatchPredictionJobDefinition
	err := ctx.RegisterResource("datarobot:index/batchPredictionJobDefinition:BatchPredictionJobDefinition", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetBatchPredictionJobDefinition gets an existing BatchPredictionJobDefinition resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetBatchPredictionJobDefinition(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *BatchPredictionJobDefinitionState, opts ...pulumi.ResourceOption) (*BatchPredictionJobDefinition, error) {
	var resource BatchPredictionJobDefinition
	err := ctx.ReadResource("datarobot:index/batchPredictionJobDefinition:BatchPredictionJobDefinition", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering BatchPredictionJobDefinition resources.
type batchPredictionJobDefinitionState struct {
	// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
	AbortOnError *bool `pulumi:"abortOnError"`
	// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
	ChunkSize interface{} `pulumi:"chunkSize"`
	// Mapping with column renaming for output table.
	ColumnNamesRemapping map[string]string `pulumi:"columnNamesRemapping"`
	// CSV intake and output settings.
	CsvSettings *BatchPredictionJobDefinitionCsvSettings `pulumi:"csvSettings"`
	// The ID of the deployment to use for the batch prediction job.
	DeploymentId *string `pulumi:"deploymentId"`
	// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
	Enabled *bool `pulumi:"enabled"`
	// Which algorithm will be used to calculate prediction explanations.
	ExplanationAlgorithm *string `pulumi:"explanationAlgorithm"`
	// Include the predictionStatus column in the output. Defaults to False.
	IncludePredictionStatus *bool `pulumi:"includePredictionStatus"`
	// Flag that enables returning of all probability columns. Defaults to True.
	IncludeProbabilities *bool `pulumi:"includeProbabilities"`
	// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
	IncludeProbabilitiesClasses []string `pulumi:"includeProbabilitiesClasses"`
	// A dict configuring how data is coming from.
	IntakeSettings *BatchPredictionJobDefinitionIntakeSettings `pulumi:"intakeSettings"`
	// Compute prediction explanations for this amount of features.
	MaxExplanations *int `pulumi:"maxExplanations"`
	// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
	Name *string `pulumi:"name"`
	// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
	NumConcurrent *int `pulumi:"numConcurrent"`
	// A dict configuring how scored data is to be saved.
	OutputSettings *BatchPredictionJobDefinitionOutputSettings `pulumi:"outputSettings"`
	// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
	PassthroughColumns []string `pulumi:"passthroughColumns"`
	// To pass through every column from the scoring dataset, set this to all.
	PassthroughColumnsSet *string `pulumi:"passthroughColumnsSet"`
	// Defaults to instance specified by deployment or system configuration.
	PredictionInstance *BatchPredictionJobDefinitionPredictionInstance `pulumi:"predictionInstance"`
	// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
	PredictionThreshold *float64 `pulumi:"predictionThreshold"`
	// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
	PredictionWarningEnabled *bool `pulumi:"predictionWarningEnabled"`
	// Defines at what intervals the job should run.
	Schedule *BatchPredictionJobDefinitionSchedule `pulumi:"schedule"`
	// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
	SkipDriftTracking *bool `pulumi:"skipDriftTracking"`
	// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
	ThresholdHigh *float64 `pulumi:"thresholdHigh"`
	// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
	ThresholdLow *float64 `pulumi:"thresholdLow"`
	// Configuration for time-series scoring.
	TimeseriesSettings *BatchPredictionJobDefinitionTimeseriesSettings `pulumi:"timeseriesSettings"`
}

type BatchPredictionJobDefinitionState struct {
	// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
	AbortOnError pulumi.BoolPtrInput
	// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
	ChunkSize pulumi.Input
	// Mapping with column renaming for output table.
	ColumnNamesRemapping pulumi.StringMapInput
	// CSV intake and output settings.
	CsvSettings BatchPredictionJobDefinitionCsvSettingsPtrInput
	// The ID of the deployment to use for the batch prediction job.
	DeploymentId pulumi.StringPtrInput
	// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
	Enabled pulumi.BoolPtrInput
	// Which algorithm will be used to calculate prediction explanations.
	ExplanationAlgorithm pulumi.StringPtrInput
	// Include the predictionStatus column in the output. Defaults to False.
	IncludePredictionStatus pulumi.BoolPtrInput
	// Flag that enables returning of all probability columns. Defaults to True.
	IncludeProbabilities pulumi.BoolPtrInput
	// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
	IncludeProbabilitiesClasses pulumi.StringArrayInput
	// A dict configuring how data is coming from.
	IntakeSettings BatchPredictionJobDefinitionIntakeSettingsPtrInput
	// Compute prediction explanations for this amount of features.
	MaxExplanations pulumi.IntPtrInput
	// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
	Name pulumi.StringPtrInput
	// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
	NumConcurrent pulumi.IntPtrInput
	// A dict configuring how scored data is to be saved.
	OutputSettings BatchPredictionJobDefinitionOutputSettingsPtrInput
	// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
	PassthroughColumns pulumi.StringArrayInput
	// To pass through every column from the scoring dataset, set this to all.
	PassthroughColumnsSet pulumi.StringPtrInput
	// Defaults to instance specified by deployment or system configuration.
	PredictionInstance BatchPredictionJobDefinitionPredictionInstancePtrInput
	// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
	PredictionThreshold pulumi.Float64PtrInput
	// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
	PredictionWarningEnabled pulumi.BoolPtrInput
	// Defines at what intervals the job should run.
	Schedule BatchPredictionJobDefinitionSchedulePtrInput
	// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
	SkipDriftTracking pulumi.BoolPtrInput
	// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
	ThresholdHigh pulumi.Float64PtrInput
	// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
	ThresholdLow pulumi.Float64PtrInput
	// Configuration for time-series scoring.
	TimeseriesSettings BatchPredictionJobDefinitionTimeseriesSettingsPtrInput
}

func (BatchPredictionJobDefinitionState) ElementType() reflect.Type {
	return reflect.TypeOf((*batchPredictionJobDefinitionState)(nil)).Elem()
}

type batchPredictionJobDefinitionArgs struct {
	// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
	AbortOnError *bool `pulumi:"abortOnError"`
	// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
	ChunkSize interface{} `pulumi:"chunkSize"`
	// Mapping with column renaming for output table.
	ColumnNamesRemapping map[string]string `pulumi:"columnNamesRemapping"`
	// CSV intake and output settings.
	CsvSettings *BatchPredictionJobDefinitionCsvSettings `pulumi:"csvSettings"`
	// The ID of the deployment to use for the batch prediction job.
	DeploymentId string `pulumi:"deploymentId"`
	// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
	Enabled *bool `pulumi:"enabled"`
	// Which algorithm will be used to calculate prediction explanations.
	ExplanationAlgorithm *string `pulumi:"explanationAlgorithm"`
	// Include the predictionStatus column in the output. Defaults to False.
	IncludePredictionStatus *bool `pulumi:"includePredictionStatus"`
	// Flag that enables returning of all probability columns. Defaults to True.
	IncludeProbabilities *bool `pulumi:"includeProbabilities"`
	// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
	IncludeProbabilitiesClasses []string `pulumi:"includeProbabilitiesClasses"`
	// A dict configuring how data is coming from.
	IntakeSettings BatchPredictionJobDefinitionIntakeSettings `pulumi:"intakeSettings"`
	// Compute prediction explanations for this amount of features.
	MaxExplanations *int `pulumi:"maxExplanations"`
	// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
	Name *string `pulumi:"name"`
	// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
	NumConcurrent *int `pulumi:"numConcurrent"`
	// A dict configuring how scored data is to be saved.
	OutputSettings *BatchPredictionJobDefinitionOutputSettings `pulumi:"outputSettings"`
	// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
	PassthroughColumns []string `pulumi:"passthroughColumns"`
	// To pass through every column from the scoring dataset, set this to all.
	PassthroughColumnsSet *string `pulumi:"passthroughColumnsSet"`
	// Defaults to instance specified by deployment or system configuration.
	PredictionInstance *BatchPredictionJobDefinitionPredictionInstance `pulumi:"predictionInstance"`
	// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
	PredictionThreshold *float64 `pulumi:"predictionThreshold"`
	// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
	PredictionWarningEnabled *bool `pulumi:"predictionWarningEnabled"`
	// Defines at what intervals the job should run.
	Schedule *BatchPredictionJobDefinitionSchedule `pulumi:"schedule"`
	// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
	SkipDriftTracking *bool `pulumi:"skipDriftTracking"`
	// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
	ThresholdHigh *float64 `pulumi:"thresholdHigh"`
	// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
	ThresholdLow *float64 `pulumi:"thresholdLow"`
	// Configuration for time-series scoring.
	TimeseriesSettings *BatchPredictionJobDefinitionTimeseriesSettings `pulumi:"timeseriesSettings"`
}

// The set of arguments for constructing a BatchPredictionJobDefinition resource.
type BatchPredictionJobDefinitionArgs struct {
	// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
	AbortOnError pulumi.BoolPtrInput
	// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
	ChunkSize pulumi.Input
	// Mapping with column renaming for output table.
	ColumnNamesRemapping pulumi.StringMapInput
	// CSV intake and output settings.
	CsvSettings BatchPredictionJobDefinitionCsvSettingsPtrInput
	// The ID of the deployment to use for the batch prediction job.
	DeploymentId pulumi.StringInput
	// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
	Enabled pulumi.BoolPtrInput
	// Which algorithm will be used to calculate prediction explanations.
	ExplanationAlgorithm pulumi.StringPtrInput
	// Include the predictionStatus column in the output. Defaults to False.
	IncludePredictionStatus pulumi.BoolPtrInput
	// Flag that enables returning of all probability columns. Defaults to True.
	IncludeProbabilities pulumi.BoolPtrInput
	// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
	IncludeProbabilitiesClasses pulumi.StringArrayInput
	// A dict configuring how data is coming from.
	IntakeSettings BatchPredictionJobDefinitionIntakeSettingsInput
	// Compute prediction explanations for this amount of features.
	MaxExplanations pulumi.IntPtrInput
	// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
	Name pulumi.StringPtrInput
	// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
	NumConcurrent pulumi.IntPtrInput
	// A dict configuring how scored data is to be saved.
	OutputSettings BatchPredictionJobDefinitionOutputSettingsPtrInput
	// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
	PassthroughColumns pulumi.StringArrayInput
	// To pass through every column from the scoring dataset, set this to all.
	PassthroughColumnsSet pulumi.StringPtrInput
	// Defaults to instance specified by deployment or system configuration.
	PredictionInstance BatchPredictionJobDefinitionPredictionInstancePtrInput
	// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
	PredictionThreshold pulumi.Float64PtrInput
	// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
	PredictionWarningEnabled pulumi.BoolPtrInput
	// Defines at what intervals the job should run.
	Schedule BatchPredictionJobDefinitionSchedulePtrInput
	// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
	SkipDriftTracking pulumi.BoolPtrInput
	// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
	ThresholdHigh pulumi.Float64PtrInput
	// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
	ThresholdLow pulumi.Float64PtrInput
	// Configuration for time-series scoring.
	TimeseriesSettings BatchPredictionJobDefinitionTimeseriesSettingsPtrInput
}

func (BatchPredictionJobDefinitionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*batchPredictionJobDefinitionArgs)(nil)).Elem()
}

type BatchPredictionJobDefinitionInput interface {
	pulumi.Input

	ToBatchPredictionJobDefinitionOutput() BatchPredictionJobDefinitionOutput
	ToBatchPredictionJobDefinitionOutputWithContext(ctx context.Context) BatchPredictionJobDefinitionOutput
}

func (*BatchPredictionJobDefinition) ElementType() reflect.Type {
	return reflect.TypeOf((**BatchPredictionJobDefinition)(nil)).Elem()
}

func (i *BatchPredictionJobDefinition) ToBatchPredictionJobDefinitionOutput() BatchPredictionJobDefinitionOutput {
	return i.ToBatchPredictionJobDefinitionOutputWithContext(context.Background())
}

func (i *BatchPredictionJobDefinition) ToBatchPredictionJobDefinitionOutputWithContext(ctx context.Context) BatchPredictionJobDefinitionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BatchPredictionJobDefinitionOutput)
}

// BatchPredictionJobDefinitionArrayInput is an input type that accepts BatchPredictionJobDefinitionArray and BatchPredictionJobDefinitionArrayOutput values.
// You can construct a concrete instance of `BatchPredictionJobDefinitionArrayInput` via:
//
//	BatchPredictionJobDefinitionArray{ BatchPredictionJobDefinitionArgs{...} }
type BatchPredictionJobDefinitionArrayInput interface {
	pulumi.Input

	ToBatchPredictionJobDefinitionArrayOutput() BatchPredictionJobDefinitionArrayOutput
	ToBatchPredictionJobDefinitionArrayOutputWithContext(context.Context) BatchPredictionJobDefinitionArrayOutput
}

type BatchPredictionJobDefinitionArray []BatchPredictionJobDefinitionInput

func (BatchPredictionJobDefinitionArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*BatchPredictionJobDefinition)(nil)).Elem()
}

func (i BatchPredictionJobDefinitionArray) ToBatchPredictionJobDefinitionArrayOutput() BatchPredictionJobDefinitionArrayOutput {
	return i.ToBatchPredictionJobDefinitionArrayOutputWithContext(context.Background())
}

func (i BatchPredictionJobDefinitionArray) ToBatchPredictionJobDefinitionArrayOutputWithContext(ctx context.Context) BatchPredictionJobDefinitionArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BatchPredictionJobDefinitionArrayOutput)
}

// BatchPredictionJobDefinitionMapInput is an input type that accepts BatchPredictionJobDefinitionMap and BatchPredictionJobDefinitionMapOutput values.
// You can construct a concrete instance of `BatchPredictionJobDefinitionMapInput` via:
//
//	BatchPredictionJobDefinitionMap{ "key": BatchPredictionJobDefinitionArgs{...} }
type BatchPredictionJobDefinitionMapInput interface {
	pulumi.Input

	ToBatchPredictionJobDefinitionMapOutput() BatchPredictionJobDefinitionMapOutput
	ToBatchPredictionJobDefinitionMapOutputWithContext(context.Context) BatchPredictionJobDefinitionMapOutput
}

type BatchPredictionJobDefinitionMap map[string]BatchPredictionJobDefinitionInput

func (BatchPredictionJobDefinitionMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*BatchPredictionJobDefinition)(nil)).Elem()
}

func (i BatchPredictionJobDefinitionMap) ToBatchPredictionJobDefinitionMapOutput() BatchPredictionJobDefinitionMapOutput {
	return i.ToBatchPredictionJobDefinitionMapOutputWithContext(context.Background())
}

func (i BatchPredictionJobDefinitionMap) ToBatchPredictionJobDefinitionMapOutputWithContext(ctx context.Context) BatchPredictionJobDefinitionMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BatchPredictionJobDefinitionMapOutput)
}

type BatchPredictionJobDefinitionOutput struct{ *pulumi.OutputState }

func (BatchPredictionJobDefinitionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**BatchPredictionJobDefinition)(nil)).Elem()
}

func (o BatchPredictionJobDefinitionOutput) ToBatchPredictionJobDefinitionOutput() BatchPredictionJobDefinitionOutput {
	return o
}

func (o BatchPredictionJobDefinitionOutput) ToBatchPredictionJobDefinitionOutputWithContext(ctx context.Context) BatchPredictionJobDefinitionOutput {
	return o
}

// Default behavior is to abort the job if too many rows fail scoring. This will free up resources for other jobs that may score successfully. Set to false to unconditionally score every row no matter how many errors are encountered. Defaults to True.
func (o BatchPredictionJobDefinitionOutput) AbortOnError() pulumi.BoolOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.BoolOutput { return v.AbortOnError }).(pulumi.BoolOutput)
}

// Which strategy should be used to determine the chunk size. Can be either a named strategy or a fixed size in bytes.
func (o BatchPredictionJobDefinitionOutput) ChunkSize() pulumi.AnyOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.AnyOutput { return v.ChunkSize }).(pulumi.AnyOutput)
}

// Mapping with column renaming for output table.
func (o BatchPredictionJobDefinitionOutput) ColumnNamesRemapping() pulumi.StringMapOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.StringMapOutput { return v.ColumnNamesRemapping }).(pulumi.StringMapOutput)
}

// CSV intake and output settings.
func (o BatchPredictionJobDefinitionOutput) CsvSettings() BatchPredictionJobDefinitionCsvSettingsOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) BatchPredictionJobDefinitionCsvSettingsOutput {
		return v.CsvSettings
	}).(BatchPredictionJobDefinitionCsvSettingsOutput)
}

// The ID of the deployment to use for the batch prediction job.
func (o BatchPredictionJobDefinitionOutput) DeploymentId() pulumi.StringOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.StringOutput { return v.DeploymentId }).(pulumi.StringOutput)
}

// Whether or not the job definition should be active on a scheduled basis. If True, schedule is required.
func (o BatchPredictionJobDefinitionOutput) Enabled() pulumi.BoolOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.BoolOutput { return v.Enabled }).(pulumi.BoolOutput)
}

// Which algorithm will be used to calculate prediction explanations.
func (o BatchPredictionJobDefinitionOutput) ExplanationAlgorithm() pulumi.StringOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.StringOutput { return v.ExplanationAlgorithm }).(pulumi.StringOutput)
}

// Include the predictionStatus column in the output. Defaults to False.
func (o BatchPredictionJobDefinitionOutput) IncludePredictionStatus() pulumi.BoolOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.BoolOutput { return v.IncludePredictionStatus }).(pulumi.BoolOutput)
}

// Flag that enables returning of all probability columns. Defaults to True.
func (o BatchPredictionJobDefinitionOutput) IncludeProbabilities() pulumi.BoolOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.BoolOutput { return v.IncludeProbabilities }).(pulumi.BoolOutput)
}

// List the subset of classes if a user doesn’t want all the classes. Defaults to [].
func (o BatchPredictionJobDefinitionOutput) IncludeProbabilitiesClasses() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.StringArrayOutput { return v.IncludeProbabilitiesClasses }).(pulumi.StringArrayOutput)
}

// A dict configuring how data is coming from.
func (o BatchPredictionJobDefinitionOutput) IntakeSettings() BatchPredictionJobDefinitionIntakeSettingsOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) BatchPredictionJobDefinitionIntakeSettingsOutput {
		return v.IntakeSettings
	}).(BatchPredictionJobDefinitionIntakeSettingsOutput)
}

// Compute prediction explanations for this amount of features.
func (o BatchPredictionJobDefinitionOutput) MaxExplanations() pulumi.IntOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.IntOutput { return v.MaxExplanations }).(pulumi.IntOutput)
}

// The name you want your job to be identified with. Must be unique across the organization’s existing jobs.
func (o BatchPredictionJobDefinitionOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// Number of concurrent chunks to score simultaneously. Defaults to the available number of cores of the deployment. Lower it to leave resources for real-time scoring.
func (o BatchPredictionJobDefinitionOutput) NumConcurrent() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.IntPtrOutput { return v.NumConcurrent }).(pulumi.IntPtrOutput)
}

// A dict configuring how scored data is to be saved.
func (o BatchPredictionJobDefinitionOutput) OutputSettings() BatchPredictionJobDefinitionOutputSettingsOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) BatchPredictionJobDefinitionOutputSettingsOutput {
		return v.OutputSettings
	}).(BatchPredictionJobDefinitionOutputSettingsOutput)
}

// Keep these columns from the scoring dataset in the scored dataset. This is useful for correlating predictions with source data.
func (o BatchPredictionJobDefinitionOutput) PassthroughColumns() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.StringArrayOutput { return v.PassthroughColumns }).(pulumi.StringArrayOutput)
}

// To pass through every column from the scoring dataset, set this to all.
func (o BatchPredictionJobDefinitionOutput) PassthroughColumnsSet() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.StringPtrOutput { return v.PassthroughColumnsSet }).(pulumi.StringPtrOutput)
}

// Defaults to instance specified by deployment or system configuration.
func (o BatchPredictionJobDefinitionOutput) PredictionInstance() BatchPredictionJobDefinitionPredictionInstancePtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) BatchPredictionJobDefinitionPredictionInstancePtrOutput {
		return v.PredictionInstance
	}).(BatchPredictionJobDefinitionPredictionInstancePtrOutput)
}

// Threshold is the point that sets the class boundary for a predicted value. This value can be set between 0.0 and 1.0.
func (o BatchPredictionJobDefinitionOutput) PredictionThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.Float64PtrOutput { return v.PredictionThreshold }).(pulumi.Float64PtrOutput)
}

// Add prediction warnings to the scored data. Currently only supported for regression models. Defaults to False.
func (o BatchPredictionJobDefinitionOutput) PredictionWarningEnabled() pulumi.BoolOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.BoolOutput { return v.PredictionWarningEnabled }).(pulumi.BoolOutput)
}

// Defines at what intervals the job should run.
func (o BatchPredictionJobDefinitionOutput) Schedule() BatchPredictionJobDefinitionSchedulePtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) BatchPredictionJobDefinitionSchedulePtrOutput { return v.Schedule }).(BatchPredictionJobDefinitionSchedulePtrOutput)
}

// Skips drift tracking on any predictions made from this job. This is useful when running non-production workloads to not affect drift tracking and cause unnecessary alerts. Defaults to false.
func (o BatchPredictionJobDefinitionOutput) SkipDriftTracking() pulumi.BoolOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.BoolOutput { return v.SkipDriftTracking }).(pulumi.BoolOutput)
}

// Only compute prediction explanations for predictions above this threshold. Can be combined with threshold_low.
func (o BatchPredictionJobDefinitionOutput) ThresholdHigh() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.Float64PtrOutput { return v.ThresholdHigh }).(pulumi.Float64PtrOutput)
}

// Only compute prediction explanations for predictions below this threshold. Can be combined with threshold_high.
func (o BatchPredictionJobDefinitionOutput) ThresholdLow() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) pulumi.Float64PtrOutput { return v.ThresholdLow }).(pulumi.Float64PtrOutput)
}

// Configuration for time-series scoring.
func (o BatchPredictionJobDefinitionOutput) TimeseriesSettings() BatchPredictionJobDefinitionTimeseriesSettingsPtrOutput {
	return o.ApplyT(func(v *BatchPredictionJobDefinition) BatchPredictionJobDefinitionTimeseriesSettingsPtrOutput {
		return v.TimeseriesSettings
	}).(BatchPredictionJobDefinitionTimeseriesSettingsPtrOutput)
}

type BatchPredictionJobDefinitionArrayOutput struct{ *pulumi.OutputState }

func (BatchPredictionJobDefinitionArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*BatchPredictionJobDefinition)(nil)).Elem()
}

func (o BatchPredictionJobDefinitionArrayOutput) ToBatchPredictionJobDefinitionArrayOutput() BatchPredictionJobDefinitionArrayOutput {
	return o
}

func (o BatchPredictionJobDefinitionArrayOutput) ToBatchPredictionJobDefinitionArrayOutputWithContext(ctx context.Context) BatchPredictionJobDefinitionArrayOutput {
	return o
}

func (o BatchPredictionJobDefinitionArrayOutput) Index(i pulumi.IntInput) BatchPredictionJobDefinitionOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *BatchPredictionJobDefinition {
		return vs[0].([]*BatchPredictionJobDefinition)[vs[1].(int)]
	}).(BatchPredictionJobDefinitionOutput)
}

type BatchPredictionJobDefinitionMapOutput struct{ *pulumi.OutputState }

func (BatchPredictionJobDefinitionMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*BatchPredictionJobDefinition)(nil)).Elem()
}

func (o BatchPredictionJobDefinitionMapOutput) ToBatchPredictionJobDefinitionMapOutput() BatchPredictionJobDefinitionMapOutput {
	return o
}

func (o BatchPredictionJobDefinitionMapOutput) ToBatchPredictionJobDefinitionMapOutputWithContext(ctx context.Context) BatchPredictionJobDefinitionMapOutput {
	return o
}

func (o BatchPredictionJobDefinitionMapOutput) MapIndex(k pulumi.StringInput) BatchPredictionJobDefinitionOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *BatchPredictionJobDefinition {
		return vs[0].(map[string]*BatchPredictionJobDefinition)[vs[1].(string)]
	}).(BatchPredictionJobDefinitionOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*BatchPredictionJobDefinitionInput)(nil)).Elem(), &BatchPredictionJobDefinition{})
	pulumi.RegisterInputType(reflect.TypeOf((*BatchPredictionJobDefinitionArrayInput)(nil)).Elem(), BatchPredictionJobDefinitionArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*BatchPredictionJobDefinitionMapInput)(nil)).Elem(), BatchPredictionJobDefinitionMap{})
	pulumi.RegisterOutputType(BatchPredictionJobDefinitionOutput{})
	pulumi.RegisterOutputType(BatchPredictionJobDefinitionArrayOutput{})
	pulumi.RegisterOutputType(BatchPredictionJobDefinitionMapOutput{})
}
